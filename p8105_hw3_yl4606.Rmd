---
title: "p8105_hw3_yl4606"
author: "Yubei Liang"
date: "10/9/2020"
output: github_document
---

```{r include=FALSE}
library(tidyverse)
library(p8105.datasets)
knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

1. How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```
There are 134 aisles and fresh vegetables are the one most items from.

2. Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


3. Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


4. Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

### Porblem 2

Load and tidy the data.
```{r message=FALSE}
accelerometer_df = 
  read_csv(
    "./Data/accel_data.csv"
    ) %>% 
  janitor::clean_names()

accelerometer_df =
  accelerometer_df %>% 
      pivot_longer(
        activity_1:activity_1440,
        names_to = "minute",
        values_to = "activity"
      ) %>%
    separate(minute, into = c("act", "minute"), sep = 9) %>%
    mutate(
      minute = as.integer(minute),
      day = as.factor(day),
      day = fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
      weekday_vs_weekend = recode(day,
        "Monday" = "weekday",
        "Tueday" = "weekday",
        "Wednesday" = "weekday",
        "Thursday" = "weekday",
        "Friday" = "weekday",
        "Saturday" = "weekend",
        "Sunday" = "weekend"
      ))%>%
    group_by(day_id) %>% 
    arrange(week, day) %>% 
    relocate(week, day, weekday_vs_weekend) %>% 
    ungroup() %>% 
    select(week, day, weekday_vs_weekend, minute, activity)

accelerometer_df
```

The existing variables include `r names(accelerometer_df)`, and the size of dataset is `r nrow(accelerometer_df)` rows by `r ncol(accelerometer_df)` columns. Therefore, there are `r nrow(accelerometer_df)` observations. The variable 'day_id' is removed because it can be replaced by combination of (week, day).


```{r}
accelerometer_df %>% 
  group_by(week, day) %>% 
  mutate(total_activity = sum(activity)) %>% 
  distinct(week, day, total_activity) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activity
  ) %>% 
  knitr::kable()
```

To be honest, I did not observe any trends except that the man is not active on Saturday of both week 4 and week 5.

```{r}
accelerometer_df %>%
  ggplot(aes(x = factor(minute), y = activity, color = day)) +
  geom_line(alpha = 0.6) +
  scale_x_discrete(breaks = seq(0, 1440, by = 60)) +
  xlab("minute in a day")
```

From the plot above, we can observe a low activity (<2500) period from midnight to 6 am, which could be resulted from sleep during the night. And an increase in activity around 11 am to noon is observed on Sunday. Moreover, a significant increase in activity from 8pm to 10pm is observed on Thursday and Friday. The highest amount of activity is on Wednesday night. The overall activity level is constant, which is below 2500 and above 1250, during the day time.

### Problem 3

Load the data.

```{r}
data("ny_noaa")
```

The size of ny_noaa dataset is `r nrow(ny_noaa)` rows by `r ncol(ny_noaa)` columns. Key variables include date, prcp, snow, snwd, tmax and tmin. Therefore, both precipitation and snow depth are recorded for each day from `r min(ny_noaa$date)` to `r max(ny_noaa$date)`. Many values in tmin and tmax are missing, and some values in prcp, snow, snwd are missing.

Tidy the data.
```{r warning=FALSE}
ny_noaa_df = 
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = '-') %>% 
  mutate(
    prcp = prcp/10,
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10
  )
  
ny_noaa_df %>% 
  drop_na(snow) %>% 
  group_by(snow) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
```

After dropping NAs of snow column, the most commonly observed values are 0mm, 25mm and 13mm. 0mm is the most common value because most of the time in NY state during a year is not snowing except in winter. 

```{r}
ny_noaa_df %>% 
  group_by(id, year, month) %>% 
  filter(month == "01" | month == "07") %>% 
  mutate(tmax = as.numeric(tmax)) %>% 
  drop_na(tmax) %>% 
  summarise(mean = mean(tmax)) %>% 
  ggplot(aes(x = year, y =  mean, group = id, color = id)) +
  geom_line(show.legend = FALSE, alpha = 0.6) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylab("mean_of_tmax") +
  facet_grid(.~month)
```

Yes. Both temperature in January and July fluctuated every two or three years, so we can conclude that temperature from 1981 to 2010 was not constant over the years. For temperature in January, there was an extreme low temperature(around -13 C) in 1982, and temperature in 1994, 2003 and 2004 seems much lower than the rest of years. And there might be an overall increase, which is not significant, in January temperature.For temperature in July, there was an extreme low temperature(around 14C) in 1988. The increase from 2009 to 2010 is obvious compared to temperature difference of other year intervals. Moreover, the two temperatures in a same year do not have to be correlated. In other word, the lowest means of max temperature in January and July do not have to appear in the same year.


